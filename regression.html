<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Regression</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">

</head>
<body>

   <!-- Elegant Animated Background -->
   <div class="food-background"></div>
   <div class="light-overlay"></div>

    <!-- üîπ Hamburger Menu Icon -->
    <div class="menu-icon" onclick="toggleMenu()">‚ò∞</div>
    <div class="navbar">
        <a href="index.html">Home</a>
        <a href="introduction.html">Introduction</a>
        <a href="data_prep.html">Data Prep</a>
        <a href="eda.html">EDA</a>        
        <a href="pca.html">PCA</a>
        <a href="clustering.html">Clustering</a>
        <a href="arm.html">ARM</a>
        <a href="decision_trees.html">Decision Trees</a>
        <a href="naive_bayes.html">Naive Bayes</a>
        <a href="svm.html">SVM</a>
        <a href="regression.html"class="active">Regression</a>
        <a href="conclusions.html">Conclusions</a>
        <a href="about_me.html">About Me</a>
    </div>

    <div class="content-section">
        <h1 id="typing-title"></h1>
        <div class="content-wrapper">

            <!-- (a) Linear Regression -->
            <h2 class="fade-in">üìà What is Linear Regression?</h2>
            <p class="fade-in">
              Linear regression is a fundamental statistical method used to model the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship, meaning the outcome can be predicted by fitting a straight line through the data points.
              The model is represented by the equation: <code>y = Œ≤‚ÇÄ + Œ≤‚ÇÅx + Œµ</code>, where <code>y</code> is the predicted value, <code>x</code> is the feature, and <code>Œµ</code> is the error term.
            </p>
            <div class="gif-section">
                <img src="assets/linear_regression_line.gif" alt="linear regression" style="max-width: 100%; border-radius: 8px; margin-top: 20px;">
            </div>
            <p class="fade-in">
              It's primarily used in regression problems‚Äîsuch as predicting calorie content from fat, protein, or sugar levels. In food science, this helps forecast nutrient totals or cost based on ingredients.
            </p>
      
            <!-- (b) Logistic Regression -->
            <h2 class="fade-in">üìâ What is Logistic Regression?</h2>
            <p class="fade-in">
              Logistic regression is used for classification problems. It predicts the probability of a sample belonging to a particular class using a logistic (sigmoid) function to transform the linear combination of inputs into a probability between 0 and 1.
            </p>
            <div class="gif-section">
                <img src="assets/logistic_regression_curve.gif" alt="logistic regression" style="max-width: 100%; border-radius: 8px; margin-top: 20px;">
            </div>
            <p class="fade-in">
              The model is defined by: <code>P(y=1) = 1 / (1 + e^-(Œ≤‚ÇÄ + Œ≤‚ÇÅx))</code>. It‚Äôs widely used in food analysis to classify items as healthy/unhealthy or vegan/non-vegan based on nutritional features.
            </p>
      
            <!-- (c) Similarities and Differences -->
            <h2 class="fade-in">üîç Similarities and Differences</h2>
            <p class="fade-in">
              Both linear and logistic regression use linear equations to model relationships between variables, and both estimate coefficients using optimization techniques.
            </p>
            <div class="image-container">
              <img src="assets/linear_vs_logistic.png" alt="Linear vs Logistic Regression" class="topic-image">
            </div>
            <p class="fade-in">
              However, linear regression predicts continuous outcomes, while logistic regression predicts probabilities for categorical outcomes. Logistic regression maps its output using the sigmoid function, whereas linear regression outputs raw values.
            </p>
      
            <!-- (d) Sigmoid Function -->
            <h2 class="fade-in">üßÆ Does Logistic Regression Use the Sigmoid Function?</h2>
            <p class="fade-in">
              Yes, logistic regression uses the sigmoid function to map any real-valued number into a value between 0 and 1. This output is interpreted as the probability of the positive class.
            </p>
            <div class="image-container">
              <img src="assets/sigmoid_function.png" alt="Sigmoid Function Plot" class="topic-image">
            </div>
            <p class="fade-in">
              The sigmoid function is defined as: <code>S(x) = 1 / (1 + e^(-x))</code>. This makes it ideal for binary classification where the goal is to predict whether a food belongs to a category (e.g., "Contains Gluten": Yes/No).
            </p>
      
            <!-- (e) Maximum Likelihood -->
            <h2 class="fade-in">üìä How is Maximum Likelihood Connected to Logistic Regression?</h2>
            <p class="fade-in">
              Logistic regression uses **Maximum Likelihood Estimation (MLE)** to find the parameters (weights) that maximize the probability of correctly classifying the training data.
            </p>
            <div class="image-container">
              <img src="assets/log_likelihood.png" alt="Log-Likelihood Maximization" class="topic-image">
            </div>
            <p class="fade-in">
              Instead of minimizing squared error (like linear regression), it maximizes the log-likelihood‚Äîa measure of how likely the observed labels are, given the model predictions. This optimization enables robust probability-based classification.
            </p>

            <!-- (f) Model Accuracy Comparison -->
            <h2 class="fade-in">üìå Comparing All Models</h2>

            <p class="fade-in">
                In this section, we performed a comprehensive comparison between six supervised learning algorithms to determine which model best classifies food categories based on their nutrient compositions. Using the same target labels and disjoint train-test splits, each model was trained on its optimal data format‚Äîcontinuous, binary, or discretized. The classifiers evaluated include: Decision Tree, Gaussian Na√Øve Bayes, Multinomial Na√Øve Bayes, Bernoulli Na√Øve Bayes, Categorical Na√Øve Bayes, and Logistic Regression. All models used a shared USDA nutrition dataset where features such as calories, protein, fat, and sugar values were normalized and preprocessed accordingly. Each model‚Äôs accuracy was computed on the test set and visually summarized in the chart below.
            </p>

            <div class="image-container fade-in">
                <img src="visuals/model_accuracy_comparison.png" alt="Model Accuracy Bar Chart" class="topic-image" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">
            </div>

            <p class="fade-in">
                The Decision Tree classifier clearly outperformed all other models, reaching an accuracy of 52.45%. This result is not surprising given that decision trees can capture complex, nonlinear interactions between nutrients‚Äîsomething probabilistic models like Na√Øve Bayes typically overlook due to their independence assumptions. Bernoulli Na√Øve Bayes followed with 35.15% accuracy, performing well because many food categories differ primarily based on the presence or absence of key nutrients. Multinomial Na√Øve Bayes (29.11%) also delivered solid results by modeling scaled count-like nutrient values, especially for distinct categories like Pizza and Candy. On the other hand, Gaussian NB (4.11%) and Categorical NB (15.78%) underperformed significantly due to mismatched assumptions: GNB presumes normal distributions, and CNB relies on discretized data which led to considerable information loss.
            </p>

            <p class="fade-in">
                Logistic Regression achieved only 23.70% accuracy‚Äîlower than expected for a multiclass problem‚Äîdue to the complex overlap between food categories that linear models struggle to separate. This comparison highlights the critical importance of choosing models aligned with the nature of the data. While probabilistic models offer speed and interpretability, tree-based models like Decision Trees can capture deeper interactions at the cost of interpretability. Ultimately, this visual and numerical comparison confirms that Decision Trees are best suited for nutrient-based food classification in this dataset, balancing accuracy, interpretability, and adaptability.
            </p>

            <div class="button-section">
                <a href="https://github.com/mrxxnal/USDA_FOODS/blob/main/compare_models.py" target="_blank" class="github-button">üîó View Comparison Code</a>
                <a href="visuals/model_accuracy_comparison.png" target="_blank" class="github-button">üìä View Accuracy Chart</a>
            </div>
    </div>

        <!-- Your existing HTML content -->

        <script>
            document.addEventListener("DOMContentLoaded", function() {
                let text = "Regression";
                let i = 0;
                function typeWriter() {
                    if (i < text.length) {
                        document.getElementById("typing-title").innerHTML += text.charAt(i);
                        i++;
                        setTimeout(typeWriter, 50);
                    }
                }
                typeWriter();
            });
        </script>

    <!-- üîπ JavaScript for Scroll-Based Fade-In Effect -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            let fadeInElements = document.querySelectorAll(".fade-in");

            function fadeInOnScroll() {
                fadeInElements.forEach(element => {
                    let position = element.getBoundingClientRect().top;
                    let screenHeight = window.innerHeight;

                    if (position < screenHeight - 100) {
                        element.classList.add("visible");
                    }
                });
            }

            window.addEventListener("scroll", fadeInOnScroll);
            fadeInOnScroll(); // Trigger on load
        });
    </script>

    <script>
        function toggleMenu() {
            var navbar = document.querySelector(".navbar");
            navbar.classList.toggle("active");
        }
    </script>
    <script type="module" src="animations.js"></script>
    <div class="transition-overlay"></div>
    <script type="module" src="animations.js"></script>
</body>
</html>